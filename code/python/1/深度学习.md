深度学习
------

+ 神经网络
>+ 神经元
>+ 激活函数: sigmoid函数、tanh函数
>+ 当激活函数的返回值是两个固定值的时候，可以成为此时的神经网络为感知器
>+ >浅层神经网络 
深度神经网络（DNN）
>+ 层数越多,效果越好 不一定 过拟合


神经网络只非线性可分


理论上来说：单隐层的神经网络可以逼近任何连续函数（只要隐层的神经元个数足够的多）

分类问题，三层的神经网络效果优于两层的神经网络，但是如果把层次不断增加，就不会有太多提高
